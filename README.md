# Sri Lanka Newspaper Bias Analysis

![Python Version](https://img.shields.io/badge/python-3.11%2B-blue)
![License](https://img.shields.io/badge/license-MIT-green)

A data-driven analysis framework for detecting media bias in Sri Lankan English newspapers by examining coverage patterns, topic distribution, and event clustering.

## Overview

This project analyzes **8,365 articles** from **4 Sri Lankan newspapers** (Daily News, The Morning, Daily FT, The Island) covering November-December 2025 to identify:

- ğŸ“° **Selection bias**: Which topics each source covers (or ignores)
- ğŸ” **Coverage patterns**: How different sources cover the same events
- ğŸ·ï¸ **Topic discovery**: Data-driven topic categorization using BERTopic
- ğŸ“Š **Event clustering**: Grouping articles about the same events across sources

## Key Findings

### Topics Discovered
- **232 topics** automatically discovered from 8,365 articles
- **77% coverage**: Successfully categorized 6,455 articles
- **Top topics**: Sri Lanka politics, flooding/disasters, sports, education, economy

### Event Clusters
- **1,717 event clusters** identified
- **87% multi-source coverage**: Most events covered by 2+ sources
- **Top event**: UN allocates $4.5M for Sri Lanka disaster relief (72 articles across 4 sources)

### Sentiment Analysis
- **Three analysis models**: Local transformer, LLM (Claude), and Hybrid approach
- **Sentiment scale**: -5 (very negative) to +5 (very positive)
- **LLM reasoning**: Detailed explanations for sentiment scores
- **Topic-sentiment correlation**: Discover how different sources frame the same topics

### Major Events (Nov-Dec 2025)
1. Cyclone Ditwah aftermath - 56 articles
2. Economic crisis response - 56 articles
3. Disaster relief fundraising - 47 articles
4. Weather warnings and flooding - multiple clusters

## Features

- ğŸ§  **Semantic embeddings**: 768-dimensional vectors using `all-mpnet-base-v2`
- ğŸ¯ **Topic modeling**: BERTopic with UMAP + HDBSCAN clustering
- ğŸ”— **Event clustering**: Cosine similarity with time-window constraints
- ğŸ˜Š **Sentiment analysis**: Three-model approach (Local, LLM, Hybrid) with reasoning
- ğŸ“ˆ **Interactive dashboard**: Streamlit-based visualization with 5 analysis tabs
- ğŸ—„ï¸ **Vector database**: PostgreSQL with pgvector extension

## Tech Stack

- **Python 3.11+**: Core language
- **PostgreSQL 16 + pgvector**: Database with vector similarity search
- **Sentence Transformers**: Local embedding generation (no API needed)
- **BERTopic**: Topic modeling with UMAP/HDBSCAN
- **Transformers + PyTorch**: Sentiment analysis with RoBERTa model
- **Claude/OpenAI API**: Optional LLM-based sentiment with reasoning
- **Streamlit**: Interactive dashboard
- **pandas, numpy**: Data processing

## Quick Start

### Prerequisites

```bash
# Database
PostgreSQL 16 with pgvector extension

# Python
Python 3.11+
```

### Setup

1. **Fork and clone the repository**
   ```bash
   git clone https://github.com/YOUR_USERNAME/sl-newspaper-bias-analysis.git
   cd sl-newspaper-bias-analysis
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure database**
   ```bash
   # Copy configuration template
   cp config.yaml.example config.yaml

   # Edit config.yaml with your database credentials
   nano config.yaml
   ```

4. **Set up database schema**
   ```bash
   psql -h localhost -U your_db_user -d your_database -f schema.sql
   ```

5. **Run the analysis pipeline**
   ```bash
   # Generate embeddings
   python3 scripts/01_generate_embeddings.py

   # Discover topics
   python3 scripts/02_discover_topics.py

   # Cluster events
   python3 scripts/03_cluster_events.py

   # Analyze sentiment (optional, choose model)
   python3 scripts/04_analyze_sentiment.py --model local  # Free, ~15 min
   # python3 scripts/04_analyze_sentiment.py --model llm    # $31, ~4-6 hours
   # python3 scripts/04_analyze_sentiment.py --model hybrid # $9, ~1-2 hours
   ```

6. **Launch dashboard**
   ```bash
   streamlit run dashboard/app.py
   # Access at http://localhost:8501
   ```

## Project Structure

```
sl-newspaper-bias-analysis/
â”œâ”€â”€ config.yaml.example     # Configuration template
â”œâ”€â”€ schema.sql              # Database schema
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ db.py              # Database operations
â”‚   â”œâ”€â”€ llm.py             # LLM client abstraction
â”‚   â”œâ”€â”€ embeddings.py      # Embedding generation
â”‚   â”œâ”€â”€ topics.py          # Topic modeling
â”‚   â”œâ”€â”€ sentiment.py       # Sentiment analysis (3 models)
â”‚   â”œâ”€â”€ clustering.py      # Event clustering
â”‚   â”œâ”€â”€ word_frequency.py  # Word frequency analysis
â”‚   â”œâ”€â”€ ner.py             # Named entity recognition
â”‚   â””â”€â”€ versions.py        # Result version management
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ topics/
â”‚   â”‚   â”œâ”€â”€ 01_generate_embeddings.py
â”‚   â”‚   â””â”€â”€ 02_discover_topics.py
â”‚   â”œâ”€â”€ clustering/
â”‚   â”‚   â”œâ”€â”€ 01_generate_embeddings.py
â”‚   â”‚   â””â”€â”€ 02_cluster_events.py
â”‚   â”œâ”€â”€ word_frequency/
â”‚   â”‚   â””â”€â”€ 01_compute_word_frequency.py
â”‚   â”œâ”€â”€ ner/
â”‚   â”‚   â””â”€â”€ 01_extract_entities.py
â”‚   â”œâ”€â”€ manage_versions.py
â”‚   â””â”€â”€ 04_analyze_sentiment.py
â””â”€â”€ dashboard/
    â””â”€â”€ app.py             # Streamlit dashboard
```

## Dashboard Preview

The dashboard includes 7 interactive views:

1. **ğŸ“Š Coverage Tab**: Article volume and timeline by source
2. **ğŸ·ï¸ Topics Tab**: Top topics and source-topic heatmap
3. **ğŸ“° Events Tab**: Browse event clusters and cross-source coverage
4. **ğŸ“ Word Frequency Tab**: Most distinctive words per source
5. **ğŸ‘¤ Named Entities Tab**: People, organizations, locations mentioned
6. **âš–ï¸ Source Comparison**: Topic focus and selection bias analysis
7. **ğŸ˜Š Sentiment Tab**: Sentiment analysis with multiple models and visualizations

## Database Schema

### Original Data
- `news_articles` - Scraped newspaper articles (8,365 articles)

### Result Versioning
- `result_versions` - Configuration-based version tracking for reproducible analysis

### Analysis Tables
- `embeddings` - Article embeddings (768-dim vectors)
- `topics` - Discovered topics (232 topics)
- `article_analysis` - Article-topic assignments
- `event_clusters` - Event clusters (1,717 clusters)
- `article_clusters` - Article-to-cluster mappings
- `word_frequencies` - Word frequency rankings per source
- `named_entities` - Extracted entities with positions and confidence
- `sentiment_analyses` - Sentiment scores for each model (local/llm/hybrid)
- `sentiment_summary` - Materialized view for performance

## Sentiment Analysis

The sentiment analysis system uses three different approaches to analyze article sentiment on a scale from -5 (very negative) to +5 (very positive).

### Three Analysis Models

#### 1. Local Transformer Model (Free)
- **Model**: `cardiffnlp/twitter-roberta-base-sentiment-latest`
- **Runtime**: ~15 minutes for 8,365 articles (CPU)
- **Cost**: Free
- **Pros**: Fast, no API needed, works offline
- **Cons**: No reasoning, less nuanced than LLM

```bash
python scripts/04_analyze_sentiment.py --model local
```

#### 2. LLM Model (Claude/OpenAI)
- **Model**: Claude Sonnet 4 (default)
- **Runtime**: ~4-6 hours for 8,365 articles
- **Cost**: ~$31 for full dataset
- **Pros**: Most accurate, provides reasoning, understands context
- **Cons**: Requires API key, costs money

```bash
# Requires ANTHROPIC_API_KEY environment variable
export ANTHROPIC_API_KEY="your-api-key"
python scripts/04_analyze_sentiment.py --model llm
```

#### 3. Hybrid Model (Best of Both)
- **Approach**: Local model + LLM fallback for low confidence
- **Runtime**: ~1-2 hours for 8,365 articles
- **Cost**: ~$9 (only ~30% use LLM)
- **Pros**: Balance of speed, cost, and accuracy
- **Cons**: Requires API key

```bash
python scripts/04_analyze_sentiment.py --model hybrid
```

### Sentiment Scale

- **-5 to -3**: Very negative (disaster, tragedy, severe criticism)
- **-2 to -1**: Somewhat negative (problems, concerns, mild criticism)
- **-0.5 to 0.5**: Neutral (factual reporting, balanced)
- **1 to 2**: Somewhat positive (progress, improvements, praise)
- **3 to 5**: Very positive (great success, celebration, strong endorsement)

### Dashboard Visualizations

The Sentiment tab in the dashboard provides:

1. **Average Sentiment by Source**: Bar chart showing which sources are more positive/negative
2. **Sentiment Distribution**: Box plots showing the range and variance
3. **Sentiment Timeline**: How sentiment changes over time
4. **Topic-Sentiment Heatmap**: Which topics are covered more positively/negatively by each source
5. **Model Comparison**: Compare agreement between different models
6. **LLM Reasoning Examples**: See detailed explanations (for LLM model)

### Cost Estimation

The script automatically estimates LLM costs before running:

```bash
python scripts/04_analyze_sentiment.py --model llm
# Shows: Estimated cost: $31.37 for 8,365 articles
# Asks for confirmation before proceeding
```

To skip the confirmation prompt:

```bash
python scripts/04_analyze_sentiment.py --model llm --skip-cost-check
```

## Research Methodology

Based on: **"The Media Bias Detector: A Framework for Annotating and Analyzing the News at Scale"** (University of Pennsylvania, 2025)

### Adaptations for Sri Lankan Context
- âœ… Topic hierarchy via data-driven discovery
- âœ… Event clustering for coverage comparison
- âœ… Selection bias analysis (topic coverage patterns)
- âœ… Sentiment analysis with multiple models
- âœ… Word frequency analysis for distinctive vocabulary
- âœ… Named entity recognition for key people and organizations
- âŒ Political lean (Democrat/Republican) - not applicable
- â¸ï¸ Framing bias analysis - future work

## Future Enhancements

### Planned Improvements
- **Article type classification**: news/opinion/analysis/editorial
- **Quote extraction**: Extract speaker information and attributions
- **Better topic labels**: LLM-generated descriptive topic names
- **Aspect-based sentiment**: Economic, political, social aspects
- **Entity sentiment**: Sentiment toward specific people/organizations
- **Fine-tuned local model**: Train on Sri Lankan news corpus
- **Real-time analysis**: Sentiment for newly scraped articles
- **CSV export**: Download analysis results

### Advanced Features
- Hierarchical topic relationships
- Time-series sentiment trends
- Quantified selection bias metrics
- Framing comparison across sources
- Sentiment alerts for unusual patterns
## Configuration

All configuration is in `config.yaml`:

```yaml
database:
  host: localhost
  name: your_database
  schema: your_schema
  user: your_db_user

embeddings:
  provider: local  # Free, no API needed
  model: all-mpnet-base-v2

clustering:
  similarity_threshold: 0.8
  time_window_days: 7

sentiment:
  enabled_models:
    - llm
    - local
    - hybrid

  llm_sentiment:
    provider: claude
    model: claude-sonnet-4-20250514
    batch_size: 10

  local_sentiment:
    model: cardiffnlp/twitter-roberta-base-sentiment-latest
    batch_size: 32
    device: cpu  # or cuda

  hybrid_sentiment:
    local_threshold: 0.7  # Use LLM if confidence < 0.7
```

## Performance

- **Embedding generation**: ~30 minutes for 8,365 articles (CPU)
- **Topic discovery**: ~2-3 minutes
- **Event clustering**: ~10 minutes
- **Word frequency**: ~5 minutes
- **Named entity recognition**: ~20 minutes
- **Sentiment analysis**:
  - Local model: ~15 minutes (CPU)
  - LLM model: ~4-6 hours ($31)
  - Hybrid model: ~1-2 hours ($9)
- **Memory usage**: ~2GB RAM during embedding generation
- **Dashboard**: All queries cached, <3 second load times

## Managing Result Versions

The project uses a version management system to track different analysis configurations. This allows you to experiment with different parameters and compare results.

### List Versions

```bash
# List all versions
python3 scripts/manage_versions.py list

# Filter by analysis type
python3 scripts/manage_versions.py list --type topics
python3 scripts/manage_versions.py list --type clustering
python3 scripts/manage_versions.py list --type word_frequency
```

### View Version Statistics

Before deleting, check what data a version contains:

```bash
python3 scripts/manage_versions.py stats <version-id>
```

This shows:
- Version metadata (name, type, description, dates)
- Data counts (embeddings, topics, clusters, etc.)
- Total records that would be affected

### Delete a Version

**Interactive deletion with safety prompts:**

```bash
python3 scripts/manage_versions.py delete <version-id>
```

This command:
- âœ… Shows version details and statistics
- âœ… Displays all data that will be deleted
- âœ… Requires you to type the version name to confirm
- âœ… Requires you to type 'DELETE' for final confirmation
- âœ… Cascade deletes all related records automatically
- âœ… **Never deletes** original articles in `news_articles` table

**What gets deleted:**
- Embeddings (embedding vectors)
- Topics (discovered topics)
- Article analyses (article-topic assignments)
- Event clusters (grouped events)
- Article-cluster mappings
- Word frequencies (if applicable)

**Programmatic deletion (Python):**

```python
# Safe interactive deletion
from src.versions import delete_version_interactive
delete_version_interactive("version-id-here")

# Direct deletion (no confirmation - use with caution!)
from src.versions import delete_version
success = delete_version("version-id-here")

# Preview what will be deleted
from src.versions import get_version_statistics
stats = get_version_statistics("version-id-here")
print(f"Will delete {sum(stats.values())} records")
```

## License

MIT License - see LICENSE file for details
